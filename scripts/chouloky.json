{
  "124": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "125": {
    "inputs": {
      "samples": [
        "136",
        0
      ],
      "vae": [
        "124",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "128": {
    "inputs": {
      "text": [
        "436",
        0
      ],
      "clip": [
        "135",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "129": {
    "inputs": {
      "width": 960,
      "height": 1920,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "130": {
    "inputs": {
      "shift": 3.1000000000000005,
      "model": [
        "133",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "132": {
    "inputs": {
      "text": [
        "434",
        0
      ],
      "clip": [
        "135",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "133": {
    "inputs": {
      "unet_name": "Qwen_Image_Distill-Q4_K_S.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "135": {
    "inputs": {
      "PowerLoraLoaderHeaderWidget": {
        "type": "PowerLoraLoaderHeaderWidget"
      },
      "lora_1": {
        "on": true,
        "lora": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
        "strength": 1
      },
      "lora_2": {
        "on": true,
        "lora": "cathy-4.safetensors",
        "strength": 0.8
      },
      "lora_3": {
        "on": true,
        "lora": "chouloky-v1_000001000.safetensors",
        "strength": 1
      },
      "➕ Add Lora": "",
      "model": [
        "130",
        0
      ],
      "clip": [
        "432",
        0
      ]
    },
    "class_type": "Power Lora Loader (rgthree)",
    "_meta": {
      "title": "Power Lora Loader (rgthree)"
    }
  },
  "136": {
    "inputs": {
      "seed": 981551602528318,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "135",
        0
      ],
      "positive": [
        "132",
        0
      ],
      "negative": [
        "128",
        0
      ],
      "latent_image": [
        "129",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "138": {
    "inputs": {
      "shift": 1.0000000000000002,
      "model": [
        "141",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "Shift"
    }
  },
  "139": {
    "inputs": {
      "text": [
        "436",
        0
      ],
      "clip": [
        "164",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "141": {
    "inputs": {
      "nag_scale": 11,
      "nag_alpha": 0.25,
      "nag_tau": 2.5,
      "input_type": "default",
      "model": [
        "164",
        0
      ],
      "conditioning": [
        "139",
        0
      ]
    },
    "class_type": "WanVideoNAG",
    "_meta": {
      "title": "WanVideoNAG"
    }
  },
  "144": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "145": {
    "inputs": {
      "samples": [
        "160",
        0
      ],
      "vae": [
        "144",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "150": {
    "inputs": {
      "text": [
        "434",
        0
      ],
      "clip": [
        "164",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "157": {
    "inputs": {
      "filename_prefix": "fixion/comfy_",
      "images": [
        "486",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "160": {
    "inputs": {
      "seed": 991429852178938,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 0.30000000000000004,
      "model": [
        "138",
        0
      ],
      "positive": [
        "150",
        0
      ],
      "negative": [
        "139",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "161": {
    "inputs": {
      "unet_name": "Wan2.2-T2V-A14B-LowNoise-Q4_K_S.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "162": {
    "inputs": {
      "clip_name": "umt5-xxl-encoder-Q5_K_S.gguf",
      "type": "wan"
    },
    "class_type": "CLIPLoaderGGUF",
    "_meta": {
      "title": "CLIPLoader (GGUF)"
    }
  },
  "164": {
    "inputs": {
      "PowerLoraLoaderHeaderWidget": {
        "type": "PowerLoraLoaderHeaderWidget"
      },
      "lora_1": {
        "on": true,
        "lora": "Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_LOW_fp16.safetensors",
        "strength": 1
      },
      "lora_2": {
        "on": false,
        "lora": "Wan2.1_T2V_14B_FusionX_LoRA.safetensors",
        "strength": 1
      },
      "➕ Add Lora": "",
      "model": [
        "161",
        0
      ],
      "clip": [
        "162",
        0
      ]
    },
    "class_type": "Power Lora Loader (rgthree)",
    "_meta": {
      "title": "Power Lora Loader (rgthree)"
    }
  },
  "167": {
    "inputs": {
      "pixels": [
        "125",
        0
      ],
      "vae": [
        "144",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "432": {
    "inputs": {
      "clip_name": "Qwen2.5-VL-7B-Instruct-UD-Q4_K_S.gguf",
      "type": "wan"
    },
    "class_type": "CLIPLoaderGGUF",
    "_meta": {
      "title": "CLIPLoader (GGUF)"
    }
  },
  "434": {
    "inputs": {
      "text1": "chouloky, a slender girl character, full body, tucked-in shirt; standing in a relaxed lean-back pose; white background, vivid colors, high-contrast cel-shading, cool energetic urban anime style.\n\nface: small droopy dark-green eyes with narrow pupils; thick black lashes and heavy smoky makeup; black eyeliner and eyeshadow under the eyes; faint blush beneath the eyes; black teardrop tattoo under one eye;\nopened mouth;\nsmall open mouth with small fang;\nevil grin showing saw tooth;\nvery short chin.\na scull shaped earing on the one side of her ear.\n\nhair: short black hair with subtle twin tails and straight-cut bangs.\n\nbody: small head, slim body proportion. slender.\nblack fingernails.\n\noutfit: a kitsch punk-style outfit on school uniform.\nschool uniform;\ntucked-in shirt;\na short pleated skirt layered over fishnet tights, and chunky platform sneakers.\nHer jacket is covered in graffiti patches, safety pins, and neon badges.\nLoose necktie hanging sideways, unbuttoned collar, rolled-up sleeves.\ngarter belt and fishnet stockings.\n\nflat lightings"
    },
    "class_type": "TextBox1",
    "_meta": {
      "title": "TextBox1"
    }
  },
  "436": {
    "inputs": {
      "text1": ""
    },
    "class_type": "TextBox1",
    "_meta": {
      "title": "TextBox1"
    }
  },
  "486": {
    "inputs": {
      "samples": [
        "136",
        0
      ],
      "vae": [
        "124",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  }
}